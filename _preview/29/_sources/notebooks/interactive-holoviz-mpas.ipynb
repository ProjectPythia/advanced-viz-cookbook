{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Holoviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Interactive plotting in a sense that you can pan and zoom the data can be helpful in may use cases as it reveals greater data fidelity within a single plot. [Holoviz](https://holoviz.org/) provides high-level tools (such as Holoviews, Datashader, and Geoviews) to perform background rendering in place of Matplotlib, which also allows us to create interactive visualizations.\n",
    "\n",
    "This notebook explores interactively plotting an unstructured grid dataset in the [MPAS](https://mpas-dev.github.io/) format with Holoviews, Datashader, and Geoviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "If you are in this notebook to learn about and/or visualize unstructured grids, we highly recommend to see also the [UXarray Cookbook](https://projectpythia.org/unstructured-grid-viz-cookbook/README.html) that is a comprehensive showcase of workflows & techniques for visualizing Unstructured Grids using [UXarray](https://uxarray.readthedocs.io/). UXarray is a Python package that:\n",
    "- Provides Xarray-styled functionality for working with unstructured grids built around the UGRID conventions\n",
    "- Supports not only MPAS but also several other formats such as UGRID, SCRIP, and Exodus\n",
    "- Enables significant data analysis and visualization functionality for unstructured grid research, which makes working with unstructured grids a breeze\n",
    "  - e.g. UXarray internally handles majority of the utility functions and data preparation steps mentioned throughout this notebook and provides user with convenient visualization and analysis functions\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates (1) making use of the MPAS format's connectivity information to render data on the native grid, and also\n",
    "avoid costly Delaunay triangulation that would be required if the MPAS connectivity information was not used; (2) rendering data that is sampled on both the 'primal' and 'dual' MPAS mesh; (3) using geoviews/holoviews for interactive plotting. Unlike Matplotlib, Datashader was designed for performance with large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Utility Functions\n",
    "2. Loading Data\n",
    "3. Using MPAS's cell connectivity array to plot primal mesh data\n",
    "4. Synthesizing triangles from points using Delaunay triangulation\n",
    "5. Using MPAS's cell connectivity array to plot dual mesh data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Holoviews](https://holoviews.org/) | Necessary | |\n",
    "| [Geoviews](https://geoviews.org/) | Useful | Not necessary for plotting but useful for adding features |\n",
    "| [Matplotlib](https://matplotlib.org/) | Useful | |\n",
    "| [MPAS](https://mpas-dev.github.io/) | Useful | Not necessary for interactive plotting but useful for understanding the data used |\n",
    "| [Xarray](https://xarray.pydata.org/) | Useful | |\n",
    "\n",
    "- **Time to learn**: 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import dask.dataframe as dd\n",
    "import geocat.datafiles as gdf  # Only for reading-in datasets\n",
    "import geoviews.feature as gf  # only needed for coastlines\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import rasterize as hds_rasterize\n",
    "from numba import jit\n",
    "from xarray import open_mfdataset\n",
    "\n",
    "hv.extension(\"bokeh\", \"matplotlib\")\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Image(frame_width=600, data_aspect=1), opts.RGB(frame_width=600, data_aspect=1)\n",
    ")\n",
    "\n",
    "n_workers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This funtion splits a global mesh along longitude\n",
    "#\n",
    "# Examine the X coordinates of each triangle in 'tris'. Return an array of 'tris' where only those triangles\n",
    "# with legs whose length is less than 't' are returned.\n",
    "#\n",
    "\n",
    "\n",
    "def unzipMesh(x, tris, t):\n",
    "    return tris[\n",
    "        (np.abs((x[tris[:, 0]]) - (x[tris[:, 1]])) < t)\n",
    "        & (np.abs((x[tris[:, 0]]) - (x[tris[:, 2]])) < t)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the signed area of a triangle\n",
    "#\n",
    "\n",
    "\n",
    "def triArea(x, y, tris):\n",
    "    return ((x[tris[:, 1]] - x[tris[:, 0]]) * (y[tris[:, 2]] - y[tris[:, 0]])) - (\n",
    "        (x[tris[:, 2]] - x[tris[:, 0]]) * (y[tris[:, 1]] - y[tris[:, 0]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reorder triangles as necessary so they all have counter clockwise winding order. CCW is what Datashader and MPL\n",
    "# require.\n",
    "#\n",
    "\n",
    "\n",
    "def orderCCW(x, y, tris):\n",
    "    tris[triArea(x, y, tris) < 0.0, :] = tris[triArea(x, y, tris) < 0.0, ::-1]\n",
    "    return tris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Holoviews Triangle Mesh suitable for rendering with Datashader\n",
    "#\n",
    "# This function returns a Holoviews TriMesh that is created from a list of coordinates, 'x' and 'y',\n",
    "# an array of triangle indices that addressess the coordinates in 'x' and 'y', and a data variable 'var'. The\n",
    "# data variable's values will annotate the triangle vertices\n",
    "#\n",
    "\n",
    "\n",
    "def createHVTriMesh(x, y, triangle_indices, var, n_workers=1):\n",
    "    # Declare verts array\n",
    "    verts = np.column_stack([x, y, var])\n",
    "\n",
    "    # Convert to pandas\n",
    "    verts_df = pd.DataFrame(verts, columns=[\"x\", \"y\", \"z\"])\n",
    "    tris_df = pd.DataFrame(triangle_indices, columns=[\"v0\", \"v1\", \"v2\"])\n",
    "\n",
    "    # Convert to dask\n",
    "    verts_ddf = dd.from_pandas(verts_df, npartitions=n_workers)\n",
    "    tris_ddf = dd.from_pandas(tris_df, npartitions=n_workers)\n",
    "\n",
    "    # Declare HoloViews element\n",
    "    tri_nodes = hv.Nodes(verts_ddf, [\"x\", \"y\", \"index\"], [\"z\"])\n",
    "    trimesh = hv.TriMesh((tris_ddf, tri_nodes))\n",
    "    return trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Triangulate MPAS primary mesh:\n",
    "#\n",
    "# Triangulate each polygon in a heterogenous mesh of n-gons by connecting\n",
    "# each internal polygon vertex to the first vertex. Uses the MPAS\n",
    "# auxilliary variables verticesOnCell, and nEdgesOnCell.\n",
    "#\n",
    "# The function is decorated with Numba's just-in-time compiler so that it is translated into\n",
    "# optimized machine code for better peformance\n",
    "#\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def triangulatePoly(verticesOnCell, nEdgesOnCell):\n",
    "    # Calculate the number of triangles. nEdgesOnCell gives the number of vertices for each cell (polygon)\n",
    "    # The number of triangles per polygon is the number of vertices minus 2.\n",
    "    #\n",
    "    nTriangles = np.sum(nEdgesOnCell - 2)\n",
    "\n",
    "    triangles = np.ones((nTriangles, 3), dtype=np.int64)\n",
    "    nCells = verticesOnCell.shape[0]\n",
    "    triIndex = 0\n",
    "    for j in range(nCells):\n",
    "        for i in range(nEdgesOnCell[j] - 2):\n",
    "            triangles[triIndex][0] = verticesOnCell[j][0]\n",
    "            triangles[triIndex][1] = verticesOnCell[j][i + 1]\n",
    "            triangles[triIndex][2] = verticesOnCell[j][i + 2]\n",
    "            triIndex += 1\n",
    "\n",
    "    return triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and coordinates\n",
    "\n",
    "The \"dyamond_1\" global datasets used in this example are courtesy of NCAR's Falko Judt and were produced as part of the \n",
    "[DYAMOND](http://dx.doi.org/10.1186/s40645-019-0304-z) initiative. They are all from the same experiment but run at several \n",
    "resolutions from 30km to 3.75km. \n",
    "\n",
    "Currently, the 30-km resolution dataset is used in this example and is available at [geocat-datafiles](https://github.com/NCAR/geocat-datafiles).\n",
    "However, the other resolutions of these data are stored on NCAR's Glade data storage because of their size. Due to their size, \n",
    "the higher resolution data sets are only distributed with two variables in them:\n",
    "\n",
    "+ relhum_200hPa: Relative humidity vertically interpolated to 200 hPa\n",
    "+ vorticity_200hPa: Relative vorticity vertically interpolated to 200 hPa\n",
    "\n",
    "The \"relhum_200hPa\" variable is computed on the MPAS 'primal' mesh, while \"vorticity_200hPa\" is computed on the MPAS\n",
    "'dual' mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "\n",
    "datafiles = (\n",
    "    gdf.get(\n",
    "        \"netcdf_files/MPAS/FalkoJudt/dyamond_1/30km/diag.2016-08-20_00.00.00_subset.nc\"\n",
    "    ),\n",
    "    gdf.get(\"netcdf_files/MPAS/FalkoJudt/dyamond_1/30km/x1.655362.grid_subset.nc\"),\n",
    ")\n",
    "\n",
    "primalVarName = \"relhum_200hPa\"\n",
    "dualVarName = \"vorticity_200hPa\"\n",
    "central_longitude = 0.0\n",
    "\n",
    "ds = open_mfdataset(datafiles, decode_times=False)\n",
    "primalVar = ds[primalVarName].isel(Time=0).values\n",
    "dualVar = ds[dualVarName].isel(Time=0).values\n",
    "\n",
    "# Fetch lat and lon coordinates for the primal and dual mesh.\n",
    "lonCell = ds[\"lonCell\"].values * 180.0 / math.pi\n",
    "latCell = ds[\"latCell\"].values * 180.0 / math.pi\n",
    "lonCell = ((lonCell - 180.0) % 360.0) - 180.0\n",
    "\n",
    "lonVertex = ds[\"lonVertex\"].values * 180.0 / math.pi\n",
    "latVertex = ds[\"latVertex\"].values * 180.0 / math.pi\n",
    "lonVertex = ((lonVertex - 180.0) % 360.0) - 180.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using MPAS's cell connectivity array to plot primal mesh data\n",
    "\n",
    "In this example we use the MPAS `cellsOnVertex` auxilliary variable, which defines mesh connectivity for the MPAS grid.\n",
    "Specifically, this variable tells us the cell IDs for each cell that contains each vertex.\n",
    "\n",
    "The benefits of this are twofold: (1) We're using the actual mesh description from the MPAS output file; (2)\n",
    "For large grid this is *much* faster than synthesizing the connectivity information as is done\n",
    "in the next example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get triangle indices for each vertex in the MPAS file. Note, indexing in MPAS starts from 1, not zero :-(\n",
    "#\n",
    "tris = ds.cellsOnVertex.values - 1\n",
    "\n",
    "# The MPAS connectivity array unforunately does not seem to guarantee consistent clockwise winding order, which\n",
    "# is required by Datashader (and Matplotlib)\n",
    "#\n",
    "tris = orderCCW(lonCell, latCell, tris)\n",
    "\n",
    "# Lastly, we need to \"unzip\" the mesh along a constant line of longitude so that when we project to PCS coordinates\n",
    "# cells don't wrap around from east to west. The function below does the job, but it assumes that the\n",
    "# central_longitude from the map projection is 0.0. I.e. it will cut the mesh where longitude\n",
    "# wraps around from -180.0 to 180.0. We'll need to generalize this\n",
    "#\n",
    "tris = unzipMesh(lonCell, tris, 90.0)\n",
    "\n",
    "\n",
    "# Project verts from geographic to PCS coordinates\n",
    "#\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "xPCS, yPCS, _ = projection.transform_points(ccrs.PlateCarree(), lonCell, latCell).T\n",
    "\n",
    "\n",
    "trimesh = createHVTriMesh(xPCS, yPCS, tris, primalVar, n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use precompute so it caches the data internally\n",
    "rasterized = hds_rasterize(trimesh, aggregator=\"mean\", precompute=True)\n",
    "rasterized.opts(tools=[\"hover\"], colorbar=True, cmap=\"coolwarm\") * gf.coastline(\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The above plot is a rasterization created by Datashader and allows to interact with it via the tools (pan, box and wheel zoom, hover) to the right of the colorbar.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "Holoviz packages provide high-level, few-line visualization functions that allow to play with several arguments. For example, try changing \n",
    "the values of `aggregator` or `precompute` or explore a new argument `dynamic=False` in `hds_rasterize()`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing triangles from points using Delaunay triangulation\n",
    "\n",
    "In this example, we do not use the triangle connectivity information stored in the MPAS file. Instead, we\n",
    "use Matplotlib's Delaunay triangulation to artifically create a triangle mesh. The benefit of this approach is that we do not\n",
    "need the MPAS `cellsOnVertex` variable if it is not available. Also, since the triangulation algorithm is run on the \n",
    "coordinates after they are projected to meters we do not have to worry about wraparound. The downside is that for\n",
    "high-resolution data, Delaunay triangulation is prohibitively expensive. The highest resolution data set mentioned\n",
    "in this notebook (3.75km) will not triangulate in a reasonable amount of time, if at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Delaunay triangulation to generate the triangle connectivity. Note, it's important that the coordinate\n",
    "# arrays already be in PCS coordinates (not lat-lon) for the triangulation to perform optimally\n",
    "\n",
    "from matplotlib.tri import Triangulation\n",
    "\n",
    "tris = Triangulation(xPCS, yPCS).triangles\n",
    "\n",
    "trimesh = createHVTriMesh(xPCS, yPCS, tris, primalVar, n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use precompute so it caches the data internally\n",
    "rasterized = hds_rasterize(trimesh, aggregator=\"mean\", precompute=True)\n",
    "rasterized.opts(tools=[\"hover\"], colorbar=True, cmap=\"coolwarm\") * gf.coastline(\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MPAS's cell connectivity array to plot dual mesh data\n",
    "\n",
    "In this final example, we use the MPAS `verticesOnCell` and `nEdgesOnCell` auxilliary variables, which defines mesh connectivity for the\n",
    "MPAS dual grid.\n",
    "\n",
    "As with the first example using the MPAS primal grid, data on the dual grid could be plotted by first\n",
    "triangulating them with, for example, Delaunay triangulation. But using grid's native connectivity information \n",
    "is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticesOnCell = ds.verticesOnCell.values - 1\n",
    "nEdgesOnCell = ds.nEdgesOnCell.values\n",
    "\n",
    "# For the dual mesh the data are located on triangle centers, which correspond to cell (polygon) vertices. Here\n",
    "# we decompose each cell into triangles\n",
    "#\n",
    "tris = triangulatePoly(verticesOnCell, nEdgesOnCell)\n",
    "\n",
    "tris = unzipMesh(lonVertex, tris, 90.0)\n",
    "\n",
    "# Project verts from geographic to PCS coordinates\n",
    "#\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "xPCS, yPCS, _ = projection.transform_points(ccrs.PlateCarree(), lonVertex, latVertex).T\n",
    "\n",
    "trimesh = createHVTriMesh(xPCS, yPCS, tris, dualVar, n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterized = hds_rasterize(trimesh, aggregator=\"mean\", precompute=True)\n",
    "rasterized.opts(tools=[\"hover\"], colorbar=True, cmap=\"coolwarm\") * gf.coastline(\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Holoviz technologies can be used in order to create interactive plots. Even though a really large dataset (e.g. km-scale) is not \n",
    "showcased in this notebook, Holoviz packages are reasonably performant with visualization of such data, too.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "The end of this notebook wraps up this cookbook. Thanks for reading!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "- [MPAS Mesh Specification](https://mpas-dev.github.io/files/documents/MPAS-MeshSpec.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
